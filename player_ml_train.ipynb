{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code repurposed for testing from \n",
    "#https://www.kaggle.com/kazmiekr/predicting-nhl-hall-of-famers/comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNBS\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import imblearn\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = pd.read_csv('Jeff/Output/test_train_file.csv')\n",
    "master_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_hof = ['Jarome Iginla', 'Marian Hossa','Martin St. Louis','Teemu Selanne','Nicklas Lidstrom','Chris Pronger','Mark Recchi','Mike Modano','Peter Forsberg']\n",
    "new_hof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop hof additions since 2011 for testing purposes\n",
    "inverse_boolean_series = ~master_df.Player.isin(new_hof)\n",
    "retired_players = master_df[inverse_boolean_series]\n",
    "\n",
    "retired_players = retired_players[retired_players['GP']>=100]\n",
    "\n",
    "#create df with only new hof additions for testing\n",
    "boolean_series = master_df.Player.isin(new_hof)\n",
    "new_hof_df = master_df[boolean_series]\n",
    "# print(new_hof_df)\n",
    "\n",
    "\n",
    "initial_eligible_players = pd.read_csv('Jeff/Output/predict_file.csv')\n",
    "\n",
    "#isolate any 'active' hof in the eligible players dataset\n",
    "active_hof = initial_eligible_players[initial_eligible_players['HoF'] == 1]\n",
    "# print(active_hof)\n",
    "#append any 'active' hof players to the test set\n",
    "new_hof_df = new_hof_df.append(active_hof)\n",
    "\n",
    "#update the eligible players df\n",
    "eligible_players = initial_eligible_players[initial_eligible_players['HoF'] == 0]\n",
    "# print(new_hof_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['Player','firstYear', 'lastYear','POS', 'HoF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(new_hof_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Set\n",
    "train=retired_players.sample(frac=0.70, random_state=16)\n",
    "# print(train.shape)\n",
    "\n",
    "#Test Set\n",
    "test=retired_players.drop(train.index)\n",
    "# print(test.shape)\n",
    "\n",
    "X_train = train.drop(cols_to_drop, axis=1)\n",
    "Y_train = train['HoF']\n",
    "X_test = test.drop(cols_to_drop, axis=1).copy()\n",
    "Y_test = test['HoF']\n",
    "\n",
    "# Dataset with unknown HoF predictions\n",
    "X_player_test = eligible_players.drop(cols_to_drop, axis=1).copy()\n",
    "\n",
    "# Create a test set of players that have made the HF since the last year of available data in this data set\n",
    "# We'll just fill the Y with 1's\n",
    "X_new_hof_test = new_hof_df.drop(cols_to_drop, axis=1).copy()\n",
    "Y_new_hof_test = np.ones(X_new_hof_test.shape[0], dtype=np.int)\n",
    "\n",
    "X_train.shape, Y_train.shape, X_test.shape, Y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {}\n",
    "# Run a classifier instance against the training set\n",
    "def run_classifier(classifier):\n",
    "    # Get the name of the classifier instance\n",
    "    class_name = classifier.__class__.__name__\n",
    "    print(\"Testing {0}\".format(class_name))\n",
    "    print(\"----------------------------------------\\n\")\n",
    "    \n",
    "    # Fit the classifier to the training set\n",
    "    classifier.fit(X_train, Y_train)\n",
    "    # Find out the training accuracy\n",
    "    training_accuracy = round(classifier.score(X_train, Y_train) * 100, 2)\n",
    "    print(\"Training Score: {0}\".format(training_accuracy))\n",
    "    \n",
    "    # Use the trained data to predict the next HoF's\n",
    "    Y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    # How accurate was it against the known set of recent HoF's\n",
    "    hof_accuracy = test_current_hf(classifier)\n",
    "    \n",
    "    # Cross validation scores\n",
    "    f1_score = f1(Y_test, Y_pred)\n",
    "    \n",
    "    \n",
    "    print(\"\\n----- Predictions -----\\n\")\n",
    "    # For all the classifiers except LinearSVC, we'll determine the probability in addition\n",
    "    # to the prediction\n",
    "    if class_name != 'LinearSVC':\n",
    "        (positive_predictions, _) = show_prediction_with_probabilities(classifier, X_player_test)\n",
    "    else:\n",
    "        (positive_predictions, _) = show_prediction(classifier, X_player_test)\n",
    "        \n",
    "    # Store our results per classifier for later analysis    \n",
    "    classifiers[class_name] = {\n",
    "        'Training Accuracy': training_accuracy,\n",
    "        'F1 Score': f1_score,\n",
    "        'Current HoF Accuracy': hof_accuracy\n",
    "    }\n",
    "    return positive_predictions\n",
    "\n",
    "# Given our set of known recent HoF additions, does the classifier think they should have made it?\n",
    "def test_current_hf(classifier):\n",
    "    accuracy = round(classifier.score(X_new_hof_test, Y_new_hof_test) * 100, 2)\n",
    "    print(\"Accuracy with Current HF: {0}\".format(accuracy))\n",
    "    return accuracy\n",
    "\n",
    "# Display from cross validation scores, F1, precision, recall\n",
    "def f1(Y_test, Y_pred):\n",
    "    macro = f1_score(Y_test.values, Y_pred, average='macro')\n",
    "    print(\"F1 Score: {0}\".format(formatPercent(macro)))\n",
    "    precision = precision_score(Y_test.values, Y_pred, average='macro')\n",
    "    print(\"Precision Score: {0}\".format(formatPercent(precision)))\n",
    "    recall = recall_score(Y_test.values, Y_pred, average='macro')\n",
    "    print(\"Recall Score: {0}\".format(formatPercent(recall)))\n",
    "    return macro\n",
    "\n",
    "def formatPercent(num):\n",
    "    return round(num, 2)\n",
    "    \n",
    "def show_prediction_with_probabilities(classifier, X_player_test, display=True):\n",
    "    prediction = classifier.predict(X_player_test)\n",
    "    prob = classifier.predict_proba(X_player_test)\n",
    "    pred_df = pd.DataFrame({\n",
    "#         \"playerID\": eligible_players[\"playerID\"],\n",
    "        \"Player\": eligible_players[\"Player\"],\n",
    "        \"isInHfPrediction\": prediction,\n",
    "        #\"prob1\": prob[:,0],\n",
    "        \"probability\": prob[:,1]\n",
    "    })\n",
    "    positive_predictions = pred_df[pred_df['isInHfPrediction'] == 1]\n",
    "    if display == True:\n",
    "        print(positive_predictions.sort_values(by='probability', ascending=False))    \n",
    "    return positive_predictions, pred_df\n",
    "\n",
    "def show_prediction(classifier, X_player_test):\n",
    "    prediction = classifier.predict(X_player_test)\n",
    "    pred_df = pd.DataFrame({\n",
    "#         \"playerID\": eligible_players[\"playerID\"],\n",
    "        \"Player\": eligible_players[\"Player\"],\n",
    "        \"isInHfPrediction\": prediction\n",
    "    })\n",
    "    positive_predictions = pred_df[pred_df['isInHfPrediction'] == 1]\n",
    "    print(positive_predictions)\n",
    "    return positive_predictions, pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = MLPClassifier(alpha=1)\n",
    "nn_pred = run_classifier(nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg_pred = run_classifier(logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(probability=True)\n",
    "svc_pred = run_classifier(svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_df = pd.DataFrame(retired_players.columns.drop(['Player','firstYear', 'lastYear','POS', 'HoF']))\n",
    "coeff_df.columns = ['Feature']\n",
    "coeff_df[\"Correlation\"] = pd.Series(logreg.coef_[0])\n",
    "\n",
    "coeff_df.sort_values(by='Correlation', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "knn_pred = run_classifier(knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian = GaussianNB()\n",
    "gaussian_pred = run_classifier(gaussian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_svc = LinearSVC()\n",
    "linear_svc_pred = run_classifier(linear_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree_pred = run_classifier(decision_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier(n_estimators=100)\n",
    "random_forest_pred = run_classifier(random_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performance = pd.DataFrame.from_dict(classifiers, orient='index')\n",
    "model_performance.sort_values(by='F1 Score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_pred.sort_values(by='probability', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
